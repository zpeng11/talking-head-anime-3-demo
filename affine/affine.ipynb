{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e1d4c9-865b-4123-a3a3-0a2bb496a0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import onnx\n",
    "from onnxsim import simplify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356bc489-5db7-4507-9425-304931fe8044",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "# open method used to open different extension image file\n",
    "im = Image.open(r\"../data/images/crypko_00.png\")\n",
    "array = np.array(im)\n",
    "im = torch.from_numpy(array).unsqueeze(0)\n",
    "angle = torch.tensor([-5])       # 旋转 30 度\n",
    "translate = torch.tensor([-50, 50])  # 向右 50 像素，向下 20 像素\n",
    "scale = 1      # 缩小到 80%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a11359d-16ab-45b4-8243-03ef9f78b0c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# https://pytorch.org/docs/stable/generated/torch.nn.functional.affine_grid.html\n",
    "# https://github.com/pytorch/pytorch/blob/master/aten/src/ATen/native/AffineGridGenerator.cpp\n",
    "def affine_grid(theta, size, align_corners=False):\n",
    "    N, C, H, W = size\n",
    "    grid = create_grid(N, C, H, W)\n",
    "    grid = grid.view(N, H * W, 3).bmm(theta.transpose(1, 2))\n",
    "    grid = grid.view(N, H, W, 2)\n",
    "    return grid\n",
    "\n",
    "def create_grid(N, C, H, W):\n",
    "    grid = torch.empty((N, H, W, 3), dtype=torch.float32)\n",
    "    grid.select(-1, 0).copy_(linspace_from_neg_one(W))\n",
    "    grid.select(-1, 1).copy_(linspace_from_neg_one(H).unsqueeze_(-1))\n",
    "    grid.select(-1, 2).fill_(1)\n",
    "    return grid\n",
    "    \n",
    "def linspace_from_neg_one(num_steps, dtype=torch.float32):\n",
    "    r = torch.linspace(-1, 1, num_steps, dtype=torch.float32)\n",
    "    r = r * (num_steps - 1) / num_steps\n",
    "    return r\n",
    "\n",
    "def patch_affine_grid_generator():\n",
    "    torch.nn.functional.affine_grid = affine_grid\n",
    "\n",
    "class AffineTransform(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.identity_matrix = torch.eye(3)\n",
    "\n",
    "    def forward(self, image, angle, translate, scale):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            image: torch.Tensor (N, H, W, C) uint8\n",
    "            angle: float 旋转角度（度）\n",
    "            translate: tuple (tx, ty) 像素单位的平移\n",
    "            scale: float 缩放因子\n",
    "        Returns:\n",
    "            torch.Tensor (N, H, W, C) uint8\n",
    "        \"\"\"\n",
    "        # 转换为float32并归一化到[0, 1]\n",
    "        x = image.float() / 255.0\n",
    "        \n",
    "        # 转换到NCHW布局\n",
    "        x = x.unsqueeze(0).permute(0, 3, 1, 2)\n",
    "        \n",
    "        # 生成仿射矩阵\n",
    "        theta = self._get_affine_matrix(x.size(), angle, translate, scale)\n",
    "        \n",
    "        # 创建采样网格\n",
    "        grid = affine_grid(theta, x.size(), align_corners=True)\n",
    "        \n",
    "        # 应用仿射变换\n",
    "        x = nn.functional.grid_sample(\n",
    "            x, \n",
    "            grid,\n",
    "            mode='bilinear',\n",
    "            padding_mode='zeros',\n",
    "            align_corners=True\n",
    "        )\n",
    "        \n",
    "        # 转换回NHWC布局\n",
    "        x = x.permute(0, 2, 3, 1).squeeze(0)\n",
    "        \n",
    "        # 转换回uint8\n",
    "        return (x.clamp(0, 1) * 255).type(torch.uint8)\n",
    "\n",
    "    def _get_affine_matrix(self, size, angle, translate, scale):\n",
    "        N, _, H, W = size\n",
    "\n",
    "        # 转换为齐次坐标的3x3矩阵\n",
    "        def create_3x3_matrix(batch_size):\n",
    "            return self.identity_matrix.unsqueeze(0).repeat(batch_size, 1, 1)\n",
    "\n",
    "        # 缩放矩阵\n",
    "        scale_matrix = create_3x3_matrix(N)\n",
    "        scale_matrix[:, 0, 0] = scale\n",
    "        scale_matrix[:, 1, 1] = scale\n",
    "\n",
    "        # 旋转矩阵\n",
    "        angle_rad = angle * torch.pi / 180.0\n",
    "        cos = torch.cos(angle_rad)\n",
    "        sin = torch.sin(angle_rad)\n",
    "        rotation_matrix = create_3x3_matrix(N)\n",
    "        rotation_matrix[:, 0, 0] = cos\n",
    "        rotation_matrix[:, 0, 1] = -sin\n",
    "        rotation_matrix[:, 1, 0] = sin\n",
    "        rotation_matrix[:, 1, 1] = cos\n",
    "\n",
    "        # 平移矩阵（考虑坐标系转换）\n",
    "        tx, ty = translate\n",
    "        translate_matrix = create_3x3_matrix(N)\n",
    "        translate_matrix[:, 0, 2] = 2.0 * tx / (W - 1)  # 转换到PyTorch坐标系\n",
    "        translate_matrix[:, 1, 2] = 2.0 * ty / (H - 1)\n",
    "\n",
    "        # 组合变换矩阵：Translate @ Rotate @ Scale\n",
    "        # 注意矩阵乘法顺序（从右到左应用变换）\n",
    "        matrix = translate_matrix @ rotation_matrix @ scale_matrix\n",
    "\n",
    "        # 提取前两行形成2x3矩阵（PyTorch要求的格式）\n",
    "        return matrix[:, :2, :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa12f271-7377-4189-a168-22f506326e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "affine = AffineTransform()\n",
    "transformed_img = affine(im.squeeze(0), angle, translate, scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d66d138-b31f-43bd-aeb4-6b4e8e3cb149",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.array(transformed_img.squeeze(0)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8e3966-4139-4170-a6a5-345cd4a0af68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导出参数\n",
    "onnx_path = \"model_static.onnx\"\n",
    "input_names = [\"img\", 'angle', 'translate','scale']    # 输入节点名称\n",
    "output_names = [\"output\"] # 输出节点名称\n",
    "\n",
    "# 执行导出\n",
    "torch.onnx.export(\n",
    "    affine,\n",
    "    (torch.randn(512,512,4).to(torch.uint8),  torch.randn((1,),dtype= torch.float32), torch.randn((2,),dtype= torch.float32),torch.randn((1,),dtype= torch.float32) ),\n",
    "    onnx_path,\n",
    "    input_names=input_names,\n",
    "    output_names=output_names,\n",
    "    opset_version=16,     # 推荐使用 opset 11+ 以获得更好兼容性\n",
    "    do_constant_folding=True,  # 优化常量折叠\n",
    "    verbose=False         # 不打印详细信息\n",
    ")\n",
    "onnx_model = onnx.load(onnx_path)\n",
    "onnx.checker.check_model(onnx_model)\n",
    "onnx_model_sim, check = simplify(onnx_model)\n",
    "if check:\n",
    "    onnx.save(onnx_model_sim, 'affine_512.onnx')\n",
    "else:\n",
    "    raise ValueError(\"Simplify error\")\n",
    "\n",
    "\n",
    "# 执行导出\n",
    "torch.onnx.export(\n",
    "    affine,\n",
    "    (torch.randn(1024,1024,4).to(torch.uint8),  torch.randn((1,),dtype= torch.float32), torch.randn((2,),dtype= torch.float32),torch.randn((1,),dtype= torch.float32) ),\n",
    "    onnx_path,\n",
    "    input_names=input_names,\n",
    "    output_names=output_names,\n",
    "    opset_version=16,     # 推荐使用 opset 11+ 以获得更好兼容性\n",
    "    do_constant_folding=True,  # 优化常量折叠\n",
    "    verbose=False         # 不打印详细信息\n",
    ")\n",
    "onnx_model = onnx.load(onnx_path)\n",
    "onnx.checker.check_model(onnx_model)\n",
    "onnx_model_sim, check = simplify(onnx_model)\n",
    "if check:\n",
    "    onnx.save(onnx_model_sim, 'affine_1024.onnx')\n",
    "else:\n",
    "    raise ValueError(\"Simplify error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8998e3bc-31c2-48a4-be7f-37b2e773b033",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from pathlib import Path\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorrt as trt\n",
    "from typing import List, Tuple\n",
    "import pycuda.driver as cuda\n",
    "import pycuda\n",
    "from os.path import join\n",
    "import numpy\n",
    "import pycuda.autoinit\n",
    "TRT_LOGGER = trt.Logger(trt.Logger.INFO)\n",
    "def build_engine(onnx_file_path, precision:str):\n",
    "    builder = trt.Builder(TRT_LOGGER)\n",
    "    network = builder.create_network()\n",
    "    config = builder.create_builder_config()\n",
    "    parser = trt.OnnxParser(network, TRT_LOGGER)\n",
    "    # Parse model file\n",
    "    TRT_LOGGER.log(TRT_LOGGER.INFO, f'Loading ONNX file from path {onnx_file_path}...')\n",
    "    with open(onnx_file_path, 'rb') as model:\n",
    "        TRT_LOGGER.log(TRT_LOGGER.INFO, 'Beginning ONNX file parsing')\n",
    "        parse_res = parser.parse(model.read())\n",
    "        if not parse_res:\n",
    "            for error in range(parser.num_errors):\n",
    "                TRT_LOGGER.log(TRT_LOGGER.ERROR, parser.get_error(error))\n",
    "            raise ValueError('Failed to parse the ONNX file.')\n",
    "    TRT_LOGGER.log(TRT_LOGGER.INFO, 'Completed parsing of ONNX file')\n",
    "    TRT_LOGGER.log(TRT_LOGGER.INFO, f'Input number: {network.num_inputs}')\n",
    "    TRT_LOGGER.log(TRT_LOGGER.INFO, f'Output number: {network.num_outputs}')\n",
    "    def GiB(val):\n",
    "        return val * 1 << 30\n",
    "    config.set_memory_pool_limit(trt.MemoryPoolType.WORKSPACE, GiB(1)) # 1G\n",
    "    \n",
    "\n",
    "    if precision == 'fp32':\n",
    "        config.set_flag(trt.BuilderFlag.TF32)\n",
    "    elif precision == 'fp16':\n",
    "        config.set_flag(trt.BuilderFlag.FP16)\n",
    "    else:\n",
    "        raise ValueError('precision must be one of fp32 or fp16')\n",
    "    \n",
    "    TRT_LOGGER.log(TRT_LOGGER.INFO, f'Building an engine from file {onnx_file_path}; this may take a while...')\n",
    "    serialized_engine = builder.build_serialized_network(network, config)\n",
    "    TRT_LOGGER.log(TRT_LOGGER.INFO, 'Completed creating Engine')\n",
    "    return serialized_engine\n",
    "\n",
    "def save_engine(engine, path):\n",
    "    TRT_LOGGER.log(TRT_LOGGER.INFO, f'Saving engine to file {path}')\n",
    "    path = Path(path)\n",
    "    path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with open(path, 'wb') as f:\n",
    "        f.write(engine)\n",
    "    TRT_LOGGER.log(TRT_LOGGER.INFO, 'Completed saving engine')\n",
    "def load_engine(path):\n",
    "    TRT_LOGGER.log(TRT_LOGGER.WARNING, f'Loading engine from file {path}')\n",
    "    runtime = trt.Runtime(TRT_LOGGER)\n",
    "    with open(path, 'rb') as f:\n",
    "        engine = runtime.deserialize_cuda_engine(f.read())\n",
    "    TRT_LOGGER.log(TRT_LOGGER.INFO, 'Completed loading engine')\n",
    "    return engine\n",
    "\n",
    "#memory management\n",
    "class HostDeviceMem(object):\n",
    "    def __init__(self, host_mem:numpy.ndarray, device_mem: pycuda.driver.DeviceAllocation):\n",
    "        self.host = host_mem\n",
    "        self.device = device_mem\n",
    "\n",
    "    def __str__(self):\n",
    "        return \"Host:\\n\" + str(self.host) + \"\\nDevice:\\n\" + str(self.device)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__str__()\n",
    "    def __del__(self):\n",
    "        self.device.free()\n",
    "    def dtoh(self, stream:pycuda.driver.Stream):\n",
    "        cuda.memcpy_dtoh_async(self.host, self.device, stream) \n",
    "    def htod(self, stream:pycuda.driver.Stream):\n",
    "        cuda.memcpy_htod_async(self.device, self.host, stream)\n",
    "\n",
    "class Processor:\n",
    "    def __init__(self, engine: trt.ICudaEngine, n_input:int):\n",
    "        self.engine = engine\n",
    "        TRT_LOGGER.log(TRT_LOGGER.INFO, 'Creating inference context')\n",
    "        # create execution context\n",
    "        self.context = engine.create_execution_context()\n",
    "        \n",
    "        # get input and output tensor names\n",
    "        self.input_tensor_names = [engine.get_tensor_name(i) for i in range(n_input)]\n",
    "        self.output_tensor_names = [engine.get_tensor_name(i) for i in range(n_input, self.engine.num_io_tensors)]\n",
    "        TRT_LOGGER.log(TRT_LOGGER.INFO, 'Input nodes: '+ str(self.input_tensor_names))\n",
    "        TRT_LOGGER.log(TRT_LOGGER.INFO, 'Output nodes: '+ str(self.output_tensor_names))\n",
    "        #create memories and bindings\n",
    "        self.inputs = []\n",
    "        self.outputs = []\n",
    "        for bindingName in engine:\n",
    "            shape = [dim for dim in self.context.get_tensor_shape(bindingName)]\n",
    "            dtype = trt.nptype(engine.get_tensor_dtype(bindingName))\n",
    "            host_mem = cuda.pagelocked_empty(shape, dtype)\n",
    "            device_mem = cuda.mem_alloc(host_mem.nbytes)\n",
    "            mem = HostDeviceMem(host_mem, device_mem)\n",
    "            self.context.set_tensor_address(bindingName, int(device_mem)) # Use this setup without binding for v3\n",
    "            if bindingName in self.input_tensor_names:\n",
    "                self.inputs.append(mem)\n",
    "            else:\n",
    "                self.outputs.append(mem)\n",
    "\n",
    "        # create stream\n",
    "        self.stream = cuda.Stream()\n",
    "        # Create a CUDA events\n",
    "        self.start_event = cuda.Event()\n",
    "        self.end_event = cuda.Event()\n",
    "\n",
    "            \n",
    "    def get_last_inference_time(self):\n",
    "        return self.start_event.time_till(self.end_event)\n",
    "\n",
    "    def loadInputs(self, inputs: List[np.ndarray]):\n",
    "        # set input shapes, the output shapes are inferred automatically\n",
    "        for inp, inp_mem in zip(inputs, self.inputs):\n",
    "            if inp.dtype != inp_mem.host.dtype or inp.shape != inp_mem.host.shape:\n",
    "                print('Given:', inp.dtype, inp.shape)\n",
    "                print('Expected:',inp_mem.host.dtype, inp_mem.host.shape)\n",
    "                raise ValueError('Input shape or type does not match')\n",
    "            np.copyto(inp_mem.host, inp)\n",
    "        for inp_mem in self.inputs: inp_mem.htod(self.stream)\n",
    "        # Synchronize the stream\n",
    "        self.stream.synchronize()\n",
    "\n",
    "    def kickoff(self):\n",
    "        # Record the start event\n",
    "        self.start_event.record(self.stream)\n",
    "        # Run inference.\n",
    "        self.context.execute_async_v3(self.stream.handle)\n",
    "        # Record the end event\n",
    "        self.end_event.record(self.stream)\n",
    "        # Synchronize the stream\n",
    "        self.stream.synchronize()\n",
    "\n",
    "    def extractOutputs(self, copy:bool = True) -> List[np.ndarray]:\n",
    "        for out_mem in self.outputs: out_mem.dtoh(self.stream)\n",
    "        # Synchronize the stream\n",
    "        self.stream.synchronize()\n",
    "        if copy:\n",
    "            return [np.copy(outp.host) for outp in self.outputs]\n",
    "        else:\n",
    "            return [outp.host for outp in self.outputs]\n",
    "        \n",
    "        \n",
    "    def inference(self, inputs: List[np.ndarray]) -> List[np.ndarray]:\n",
    "        \"\"\"\n",
    "        inference process:\n",
    "        1. create execution context\n",
    "        2. set input shapes\n",
    "        3. allocate memory\n",
    "        4. copy input data to device\n",
    "        5. run inference on device\n",
    "        6. copy output data to host and reshape\n",
    "        \"\"\"\n",
    "\n",
    "        # set input shapes, the output shapes are inferred automatically\n",
    "        for inp, inp_mem in zip(inputs, self.inputs):\n",
    "            if inp.dtype != inp_mem.host.dtype or inp.shape != inp_mem.host.shape:\n",
    "                print('Given:', inp.dtype, inp.shape)\n",
    "                print('Expected:',inp_mem.host.dtype, inp_mem.host.shape)\n",
    "                raise ValueError('Input shape or type does not match')\n",
    "            np.copyto(inp_mem.host, inp)\n",
    "\n",
    "        for inp_mem in self.inputs: inp_mem.htod(self.stream)\n",
    "            \n",
    "        # Record the start event\n",
    "        self.start_event.record(self.stream)\n",
    "        # Run inference.\n",
    "        self.context.execute_async_v3(self.stream.handle)\n",
    "        # Record the end event\n",
    "        self.end_event.record(self.stream)\n",
    "\n",
    "        for out_mem in self.outputs: out_mem.dtoh(self.stream)\n",
    "            \n",
    "        # Synchronize the stream\n",
    "        self.stream.synchronize()\n",
    "        \n",
    "        return [np.copy(outp.host) for outp in self.outputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a1000d-9964-4153-b5b6-9168d1d91fb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_engine(build_engine('affine_1024.onnx','fp32'),\n",
    "            './affine_1024.trt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff31622c-5f73-450d-8d5f-076d7b5f5b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Processor(load_engine('./affine_1024.trt'),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be6cd3f-ec04-4db2-8e6d-0a4e49605406",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "for i in tqdm(range(10000)):\n",
    "    p.kickoff()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
